{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befec7f9",
   "metadata": {},
   "source": [
    "# Plotting Emissions data from HERWIG Simulation\n",
    "Rosie Schiffmann <br>\n",
    "University of Manchester <br>\n",
    "July 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315ac9e",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "In this notebook, energy and power consumption data obtained from running particle physics event generation simulations using HERWIG is plotted. CPU and RAM energy and power consumption, alongside estimated CO2e emissions was tracked by CodeCarbon. The simulation complexity was varied across runs by changing the total number of events generated by HERWIG, and tracking was performed separately for the integration and generation phases of simulation. During the integration phase, the total cross section is calculated by numerically integrating the squared matrix elements over the allowed phase space of the process. In the generation phase, Herwig samples specific final states based on the probability distribution obtained in the integration phase, and then simulates parton showers, hadronisation, and hadron decays using Monte Carlo techniques.\n",
    "\n",
    "Data for individual runs from CodeCarbon is stored in CSV files, that follow the naming convention YYYYMMDDType_metadata_EVENTS_JOBS.csv. YYYYMMDD represents the date that the simulations were run. Type is either Int or Gen, to represent data recorded duting the integration or generation phase respectively. EVENTS is the total number of simulated events. This variable can be changed inside the run_herwig_with_cc_loop.ipynb file. JOBS represnets the number of parallel jobs for HERWIG to use, in order to speed up computation by utilising multiple cores. Data that covers the emissions produced by the entire 10 runs as a whole can be found in CSV files YYYYMMDDType_emissions_EVENTS-JOBS.csv.\n",
    "\n",
    "Plotting functions in this notebook are taken from the emission_tracking.ipynb notebook in https://github.com/rosieschiffmann/event-Transport-Simulation-Energy-Estimation github repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62db143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5b71e",
   "metadata": {},
   "source": [
    "# 2. Data Processing\n",
    "\n",
    "Here, we will assimilate all of the individual CSV files into 2 separate master CSV files: \"Int_master_emissions_data.csv\" and \"Gen_master_emissions_data.csv\". To do this, mean values were calculated for emissions, duration and CPU/GPU energy and power consumption for each raw data file corresponding to a different number of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d6bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify relevant csv files inside repository\n",
    "int_files = glob.glob(\"*Int_metadata-*-4.csv\")\n",
    "gen_files = glob.glob(\"*Gen_metadata-*-4.csv\")\n",
    "\n",
    "def generate_master_csv(files, type):\n",
    "\t\"\"\"\n",
    "\tFunction to generate a master csv file containing all data for plotting, for either the integration or generation\n",
    "\tphase of HERWIG.\n",
    "\n",
    "\tParameters:\n",
    "\t- files (list of str): list of filenames to include in master csv\n",
    "\t- type (str): \"Int\" or \"Gen\" for integration phase data or generation phase data respectively\n",
    "\t\"\"\"\n",
    "\tsummary_data = []\n",
    "\n",
    "\tfor file in files:\n",
    "\t\t#identify and find mean of relevant data from CodeCarbon raw outputs\n",
    "\t\tdf = pd.read_csv(file)\n",
    "\t\tmean_emissions = df['emissions'].mean()\n",
    "\t\tmean_duration = df['duration'].mean()\n",
    "\t\tmean_cpu_power = df['cpu_power'].mean()\n",
    "\t\tmean_ram_power = df['ram_power'].mean()\n",
    "\t\tmean_cpu_energy = df['cpu_energy'].mean()\n",
    "\t\tmean_ram_energy = df['ram_energy'].mean()\n",
    "\t\t#obtain number of events from filename\n",
    "\t\tmatch = re.search(r'_metadata-(\\d+)-4\\.csv', file)\n",
    "\t\tevents = int(match.group(1)) if match else None\n",
    "\n",
    "\t\t#propagate errors\n",
    "\t\temissions_err = df['emissions'].std() / np.sqrt(len(df['emissions']))\n",
    "\t\tduration_err = df['duration'].std() / np.sqrt(len(df['duration']))\n",
    "\t\tcpu_power_err = df['cpu_power'].std() / np.sqrt(len(df['cpu_power']))\n",
    "\t\tram_power_err = df['ram_power'].std() / np.sqrt(len(df['ram_power']))\n",
    "\t\tcpu_energy_err = df['cpu_energy'].std() / np.sqrt(len(df['cpu_energy']))\n",
    "\t\tram_energy_err = df['ram_energy'].std() / np.sqrt(len(df['ram_energy']))\n",
    "\t\t\n",
    "\t\t#add dictionary of data to summary_data list \n",
    "\t\tsummary_data.append({\n",
    "\t\t\t'filename': file,\n",
    "\t\t\t'number_of_events': events,\n",
    "\t\t\t'mean_emissions': mean_emissions,\n",
    "\t\t\t'emissions_err' : emissions_err,\n",
    "\t\t\t'mean_duration': mean_duration,\n",
    "\t\t\t'duration_err' : duration_err,\n",
    "\t\t\t'mean_cpu_power': mean_cpu_power,\n",
    "\t\t\t'cpu_power_err' : cpu_power_err,\n",
    "\t\t\t'mean_ram_power' : mean_ram_power,\n",
    "\t\t\t'ram_power_err' : ram_power_err,\n",
    "\t\t\t'mean_cpu_energy' : mean_cpu_energy,\n",
    "\t\t\t'cpu_energy_err' : cpu_energy_err,\n",
    "\t\t\t'mean_ram_energy' : mean_ram_energy,\n",
    "\t\t\t'ram_energy_err' : ram_energy_err,\n",
    "\t\t\t'cpu_energy_per_event' : mean_cpu_energy / events,\n",
    "\t\t\t'cpu_energy_per_event_err' : cpu_energy_err / events,\n",
    "\t\t\t'ram_energy_per_event' : mean_ram_energy / events,\n",
    "\t\t\t'ram_energy_per_event_err' : ram_energy_err / events,\n",
    "\t\t\t'duration_per_event' : mean_duration / events,\n",
    "\t\t\t'duration_per_event_err': duration_err / events\n",
    "\t\t})\n",
    "\n",
    "\t#convert into dataframe and create master csv file.\n",
    "\tsummary_df = pd.DataFrame(summary_data)\n",
    "\tsummary_df = summary_df.sort_values(by='number_of_events') #sort wrt number_of_events\n",
    "\tsummary_df.to_csv(f\"{type}_master_emissions_data.csv\", index=False)\n",
    "\treturn summary_df\n",
    "\n",
    "int_summary_df = generate_master_csv(int_files, \"Int\")\n",
    "gen_summary_df = generate_master_csv(gen_files, \"Gen\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
